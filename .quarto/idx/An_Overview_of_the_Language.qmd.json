{"title":"An Overview of the Language","markdown":{"yaml":{"title":"An Overview of the Language"},"headingText":"Package Management","containsRefs":false,"markdown":"\n\nJulia will open up in the default environment, e.g. `@v1.8`. You can add packages to this environment and they will be available to load as soon as you open Julia. Be very careful about doing this, as this can very often lead to what is lightly called *dependency hell*. This is what happens when a package you want to update depends on another package that can't update, sometime because it depends on a specific version of yet another package. The more packages you have in the current environment, to more often this will happen. The solution is to create a new environment for each project and add only the packages you are actually using.\n\n```\n               _\n   _       _ _(_)_     |  Documentation: https://docs.julialang.org\n  (_)     | (_) (_)    |\n   _ _   _| |_  __ _   |  Type \"?\" for help, \"]?\" for Pkg help.\n  | | | | | | |/ _` |  |\n  | | |_| | | | (_| |  |  Version 1.8.5 (2023-01-08)\n _/ |\\__'_|_|_|\\__'_|  |  Official https://julialang.org/ release\n|__/                   |\n\njulia> cd(\"./Dummy\")\n\njulia> pwd()\n\"D:\\\\JuliaCode\\\\Dummy\"\n\n(@v1.8) pkg> activate .\n  Activating project at `D:\\JuliaCode\\Dummy`\n\n(Dummy) pkg> add UnicodePlots\n    Updating registry at `C:\\Users\\Braam\\.julia\\registries\\General.toml`\n   Resolving package versions...\n    Updating `D:\\JuliaCode\\Dummy\\Project.toml`\n  [b8865327] + UnicodePlots v3.4.1\n    Updating `D:\\JuliaCode\\Dummy\\Manifest.toml`\n  [d360d2e6] + ChainRulesCore v1.15.7\n  [9e997f8a] + ChangesOfVariables v0.1.6\n  [35d6a980] + ColorSchemes v3.20.0\n  .\n  .\n  .\n\n(Dummy) pkg> st\nStatus `D:\\JuliaCode\\Dummy\\Project.toml`\n  [b8865327] UnicodePlots v3.4.1\n```\n\nHere we changed the current directory to the *Dummy* sub-folder. Note the use of a forward slash. Backslashes are used for special characters, e.g. `\\n` for a new line and must themselves be *escaped* by typing a double backslash: `cd(\".\\\\Dummy\")`. Or you can use a raw string: `cd(raw\".\\Dummy\")`. The forward slash however works just as well in Linux and MaxOS, so is preferred.\n\n`pwd()` is a function that replicates the Unix (Linux) command for *print working directory* and simply returns the name of the current folder. \n\nThe package manager is then activated with `]` and the current folder is activated as a project with `activate .`, where `.` means the current directory (`..` means the parent directory).\n\nFinally we add a registered packages, UnicodePlots.jl, and once the installation is done, check which packages and versions are currently installed with the `st` command (short for `status`).\n\nOnce a package is installed, it can be loaded by issuing the `using` command:\n\n```julia\njulia> using UnicodePlots\n```\n\nIn the `Dummy` folder, Julia creates two files: `project.toml` and `manifest.toml`. These hold the record of the specific versions of packages that have been installed. The packages directly installed are in the `project.toml` file, while the version numbers of dependencies are tracked in `manifest.toml`. These two files mean that someone else can reinstate the exact environment you developed your code in by activating the project and issuing the `instantiate` command to the package manager. This will install the same versions of the packages and dependencies as listed in the `*.toml` files.\n\nEach project should be in its own folder, with its own `*.toml` files. This means different projects can potentially use different versions of the same package, depending on what other packages are in use.\n\nTo update the packages and dependencies to the latest versions (as allowed for by the specified versions of dependencies for each packages), use the `up` command of the package manager. This updates packages for the **current** project only.\n\n## Using vs Import\n\nThere are two ways to load a Julia package: `using` and `import`\n\nIf you use `using`, all methods and variables exported by a package are brought into the current namespace. You can call them directly:\n\n```julia\nusing Plots\n\nscatter(rand(10), rand(10))\n```\n\nThis does mean that several functions and variables you are not using are now also in the namespace and you cannot define a new function with the same name, or use another package that exports a function with the same name. For those cases, you can use `import`. If a package is `import`ed, you need to prepend each function call with the package name.\n\n```julia\nimport Plots\nimport GLMakie\n\nPlots.scatter(rand(10), rand(10))\nGLMakie.scatter(rand(10), rand(10))\n```\n\n::: {.callout-tip}\n## Try this\n\nSee what happens when you use `using` for the previous example.\n:::\n\nYou can load specific functions or variables from a package:\n\n```julia\nusing Plots: scatter\nimport GLMakie: lines\n```\n\nNone of the other exported variables or functions will become available. When loading a single item, you can also rename it using the `as` keyword:\n\n```julia\nimport Plots.scatter as ps\nimport GLMakie: scatter as ms\n\nps(rand(10), rand(10))\nms(rand(10), rand(10))\n```\n\nor even rename the package during import:\n\n```julia\njulia> import BenchmarkTools as bt\n\njulia> bt.@benchmark sin.(1:1_000_000)\nBenchmarkTools.Trial: 400 samples with 1 evaluation.\n Range (min … max):  11.751 ms … 24.278 ms  ┊ GC (min … max): 0.00% … 49.13%\n Time  (median):     12.043 ms              ┊ GC (median):    0.00%\n Time  (mean ± σ):   12.515 ms ±  2.246 ms  ┊ GC (mean ± σ):  3.56% ±  9.50%\n\n  ▆█▅\n  ████▆▁▄▁▁▁▁▄▁▁▁▁▁▁▁▁▁▁▁▁▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▄▁▁▁▁▅▇▆ ▆\n  11.8 ms      Histogram: log(frequency) by time        24 ms <\n\n Memory estimate: 7.63 MiB, allocs estimate: 2.\n\n```\n\n## Variables\nThere is no programming without variables. In Julia, there is no need to pre-declare a variable and variables can be reassigned to a value of another type:\n\n```julia\njulia> x = 1\n1\n\njulia> typeof(x)\nInt64\n\njulia> x = 2.4\n2.4\n\njulia> typeof(x)\nFloat64\n\njulia> x = \"Hello, World\"\n\"Hello, World\"\n\njulia> typeof(x)\nString\n```\nWhen assigning a value to the variable `x`, Julia infers the type of the value, e.g. `Int64` and then associates the name, `x`, with that value.\n\nAs illustrated, the function `typeof()` will return the type of the variable or value.\n\n### Integers and Floating-point Values\nJulia has the usual selection of variable types for integers and floating point values. There are signed and unsigned versions of 8, 16, 32, 64 and 128-bit integers. See the [manual](https://docs.julialang.org/en/v1/manual/integers-and-floating-point-numbers/) for details.\n\nThere is also a `Bool` type that holds either `true` (1) or `false` (0).\n\nFor floating point values, there is Float16, Float32 and Float64.\n\nThe default integer, `Int` is Int64 for 64-bit Julia and `Int32` for 32-bit Julia. Generally, you would want to use `Float64` for floating-point numbers, unless there is a specific reason not to. Calculations on a GPU (via e.g. `CUDA.jl`) should be done using `Float32`.\n\n#### A Word on Floating Point Values\nFloating point values are stored in a limited number of bits (typically 64 bits - a.k.a. double precision) and hence have a limited precision. The result is that most values cannot be precisley stored in a `Float64` variable. As a simple example, 1/10, which is clearly precisely equal to 0.1, is actually calculated as 0.1000000000000000055511151231257827021181583404541015625 with 256-bit precision.\n\nThe smallest positive value that can be stored in a `Float64`, is 2.220446049250313e-16. You can calculate this in Julia using the `eps()` function, e.g. `eps(Float64)`. The value epsilon is an indication of the precision you can expect. It is the smallest value you can add to the floating point value that will cause it to result in a new value. Anything smaller may as well be zero. Obviously epsilon depends on the magnitude of the values you are working with and you can again use the `eps()` function: `eps(100) = 1.4210854715202004e-14`, so adding a smaller amount to 100 will not change the value.\n\nWhile you can safely ignore this for many, if not most engineering calculations, it can sometimes become an issue when you least expect it. Consider adding up a very large number of small values. The larger the difference between the running total and the next value you are adding, the larger the rounding error will become. At some point in this exercise, the value you are adding to the running total will be in the order of the relative epsilon and the running total will stop increasing, no matter how many more values you add. The solution to this is actually fairly simple and implemented in the Julia `sum()` function. The list of values is split into pairs and the pairs are added to each other, then this is repeated over and over until there is only one value left - the answer. The algorithm works under the inherent assumption that the values are fairly equally sized and so adding similar values results in minimal rounding error. Once the pairs have been summed, the new values should also be simialrly sized and so the process repeats, with a minimum rounding error at each step.\n\nSomething else to consider, which much more often trips up new programmers, is that you will very rarely find two identical floating point values through calculations. Directly comparing values that are realistically speaking equal, will very often result in the wrong part of an `if` statement executing. When comparing floating point values, always use a check for approximate equality. This is done either via the `≈` operator (`\\approx<tab>`), or the `isapprox()` function, which allows you to specify absolute and relative tolerances. The `≈` operator calls `isapprox()` with default tolerances.\n\nThe internal storage of floating point values is standardised by the [IEEE 754](https://en.wikipedia.org/wiki/Double-precision_floating-point_format) standard, which is used in just about every programming language.\n\n### BigInt and BigFloat\nSometimes, you may find a need for additional precision. Arbitrary precicion integer and floating point types are available as BigInt and BigFloat. \n\nThere are several ways to specifiy that you are using `big` numbers, but the simplest is via the `big()` function:\n\n```julia\njulia> x = big(10.0)\n10.0\n\njulia> typeof(x)\nBigFloat\n```\nThe precision again comes at the cost of performance. See the [manual](https://docs.julialang.org/en/v1/base/numbers/#BigFloats-and-BigInts) for more details.\n\n### Complex Numbers\nJulia has built-in types for complex numbers, which depend on the integer or floating-point type used to store the real and imaginary parts, e.g.\n\n```julia\njulia> typeof(1 + 2im)\nComplex{Int64}\n\njulia> typeof(1.0 + 2.0im)\nComplexF64 (alias for Complex{Float64})\n```\nAs you will notice, a complex type is specified as `Complex{T}` where T is an integer or floating point type. Any of the integer and floating points types mentioned before could be used, including `BigInt` and `BigFloat`. Simply define the value as:\n\n```julia\njulia> z = big(10.0) + 1.0im\n10.0 + 1.0im\n\njulia> typeof(z)\nComplex{BigFloat}\n\njulia> z = big(10) + 1im\n10 + 1im\n\njulia> typeof(z)\nComplex{BigInt}\n```\n\nThe imaginary part of the number is indicated by adding `im` directly behind the number - no space!\n\nThe standard functions used with complex numbers are available, including:\n\n```julia\njulia> z = 1 + 1im\n1 + 1im\n\njulia> real(z) # real part\n1\n\njulia> imag(z) # imaginary part\n1\n\njulia> conj(z) # complex conjugate\n1 - 1im\n\njulia> abs(z) # absolute value - distance from zero\n1.4142135623730951\n\njulia> abs2(z) # squared absolute value\n2\n\njulia> angle(z) # phase angle (radians)\n0.7853981633974483\n\njulia> angle(z) * 360/2π # convert to degrees\n45.0\n\njulia> √z\n1.09868411346781 + 0.45508986056222733im\n\njulia> sqrt(z)\n1.09868411346781 + 0.45508986056222733im\n```\n\n### Rational Numbers\nYou can also work with rational numbers. \n\n```julia\njulia> a = 1//2 + 3//8\n7//8\n\njulia> float(a)\n0.875\n\njulia> rationalize(0.875)\n7//8\n```\nThis eliminates rounding losses, but at a loss of performance:\n\n```julia\njulia> function myfunc(x)\n           sum = zero(x)\n           for i in 1:10_000\n               sum += x * i\n           end\n           return sum\n       end\n\nmyfunc (generic function with 1 method)\n\njulia> using BenchmarkTools\n\njulia> @benchmark myfunc(1.0)\nBenchmarkTools.Trial: 10000 samples with 3 evaluations.\n Range (min … max):  8.500 μs …  73.733 μs  ┊ GC (min … max): 0.00% … 0.00%\n Time  (median):     8.700 μs               ┊ GC (median):    0.00%\n Time  (mean ± σ):   8.704 μs ± 966.620 ns  ┊ GC (mean ± σ):  0.00% ± 0.00%\n\n  ▅  █  ▆  ▃         █  █   ▅  ▂  ▁   ▁  ▁                    ▂\n  █▁▁█▁▁█▁▁█▁▁▁█▁▁█▁▁█▁▁█▁▁▁█▁▁█▁▁█▁▁▁█▁▁█▁▁█▁▁█▁▁▁▇▁▁█▁▁▇▁▁▄ █\n  8.5 μs       Histogram: log(frequency) by time       9.1 μs <\n\n Memory estimate: 0 bytes, allocs estimate: 0.\n\njulia> @benchmark myfunc(1//1)\nBenchmarkTools.Trial: 7295 samples with 1 evaluation.\n Range (min … max):  663.600 μs …  1.234 ms  ┊ GC (min … max): 0.00% … 0.00%\n Time  (median):     680.100 μs              ┊ GC (median):    0.00%\n Time  (mean ± σ):   682.504 μs ± 29.021 μs  ┊ GC (mean ± σ):  0.00% ± 0.00%\n\n  ▇█▆▃▂▃██▅▄▃▃▃▂▃▁▁▁▁       ▁                                  ▂\n  ███████████████████████▇▇████▇▇█▆▆▇▇▇▅▆▆▅▆▅▅▅▃▅▅▄▆▅▃▅▅▄▄▁▃▃▅ █\n  664 μs        Histogram: log(frequency) by time       811 μs <\n\n Memory estimate: 0 bytes, allocs estimate: 0.\n ```\n\nSo, floating point calculations are about 78x faster than with rational numbers. What about integers?\n\n```julia\njulia> @benchmark myfunc(1)\nBenchmarkTools.Trial: 10000 samples with 1000 evaluations.\n Range (min … max):  1.900 ns … 27.200 ns  ┊ GC (min … max): 0.00% … 0.00%\n Time  (median):     2.000 ns              ┊ GC (median):    0.00%\n Time  (mean ± σ):   1.976 ns ±  0.530 ns  ┊ GC (mean ± σ):  0.00% ± 0.00%\n\n  ▄                                                        █\n  █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█ ▂\n  1.9 ns         Histogram: frequency by time           2 ns <\n\n Memory estimate: 0 bytes, allocs estimate: 0.\n```\n1.9 nanoseconds?!? That sounds too good to be true, doesn't it? Let's see what type of code Julia generated to make that possible.\n\n```julia\njulia> @code_llvm myfunc(1)\n;  @ REPL[6]:1 within `myfunc`\n; Function Attrs: uwtable\ndefine i64 @julia_myfunc_739(i64 signext %0) #0 {\ntop:\n;  @ REPL[6]:3 within `myfunc`\n  %1 = mul i64 %0, 50005000\n;  @ REPL[6]:6 within `myfunc`\n  ret i64 %1\n}\n```\n\nWe can again ignore any line starting with a semi-colon. The one line that matters is this:\n\n```julia\n  %1 = mul i64 %0, 50005000\n```\n\nThe Julia compiler could analyse the code well enough to see that the answer to our function is sumply 50005000 times the input value and that is exactly what it returned!\n\nWith floating point and rational values, there were type conversions required before multiplying the integer value of the loop counter with the input value. This \"hid\" the true nature of the calculation enough that the compiler could not see the short-cut. There is however continuous development in the compiler and we can reasonbly expect this to also be optimised in a future version of Julia.\n\n### Arrays, Tuples and Ranges\n#### Arrays\nIn most code, you will find it convenient to deal with a collection of values at the same time. There are several ways of doing this.\n\nThe most common collection of values is an Array. In mathematics, you will be familar with vectors and matrices. These are simply one- and two dimensional arrays. You can have arrays with any number of dimensions (*tensors*). The keywords `Vector` and `Matrix` are also available as synonyms for `Array` in the special cases of one and two dimensions.\n\nSimple one dimensional arrays are treated as column vectors for use in linear algebra calculations. You can s\nSome examples:\n\n```julia\njulia> a = [1, 2, 3]   # use commas to specify column vectors\n3-element Vector{Int64}:\n 1\n 2\n 3\n\njulia> b = [1 2 3]   # use spaces to specify row vectors\n1×3 Matrix{Int64}:\n 1  2  3\n\njulia> a * b \n3×3 Matrix{Int64}:\n 1  2  3\n 2  4  6\n 3  6  9\n\njulia> A = [1 2 3;   # directly specify a 2D array a.k.a. a matrix\n            4 5 6;\n            7 8 9]\n3×3 Matrix{Int64}:\n 1  2  3\n 4  5  6\n 7  8  9\n\njulia> B = zeros(3, 3, 3)   # zeros() and ones() fill the array of the specified size\n3×3×3 Array{Float64, 3}:\n[:, :, 1] =\n 0.0  0.0  0.0\n 0.0  0.0  0.0\n 0.0  0.0  0.0\n\n[:, :, 2] =\n 0.0  0.0  0.0\n 0.0  0.0  0.0\n 0.0  0.0  0.0\n\n[:, :, 3] =\n 0.0  0.0  0.0\n 0.0  0.0  0.0\n 0.0  0.0  0.0 \n\njulia> C = [1;2;;3;4;;;5;6;;7;8;;;9;10;;11;12]  # ; separates in first dimension, ;; in second dimension, ;;; in third etc.\n2×2×3 Array{Int64, 3}:\n[:, :, 1] =\n 1  3\n 2  4\n\n[:, :, 2] =\n 5  7\n 6  8\n\n[:, :, 3] =\n  9  11\n 10  12\n\njulia> A = Float64[]   # an empty 1D array of Float64\nFloat64[]\n```\n\nThe individual entries of an array are accessed via `[]`, e.g. \n```julia\njulia> A[2, 3]\n6\n```\nIn the background, `[]` calls  `getindex()` and `setindex()` to retrieve or modify the entries of the array. If you define your own array-like type, you will need to supply the appropriate `getindex()` and `setindex()` functions.\n\nYou can concatenate arrays horizontally and vertically with `hcat()` and `vcat()`, or using the syntax above with spaces or semi-colons:\n\n```julia\njulia> A = [1, 2, 3]\n3-element Vector{Int64}:\n 1\n 2\n 3\n\njulia> B = [4, 5, 6]\n3-element Vector{Int64}:\n 4\n 5\n 6\n\njulia> [A; B]\n6-element Vector{Int64}:\n 1\n 2\n 3\n 4\n 5\n 6\n\njulia> [A B]\n3×2 Matrix{Int64}:\n 1  4\n 2  5\n 3  6\n\njulia> vcat(A, B)\n6-element Vector{Int64}:\n 1\n 2\n 3\n 4\n 5\n 6\n\njulia> hcat(A, B)\n3×2 Matrix{Int64}:\n 1  4\n 2  5\n 3  6\n```\n#### Tuples\nTuples are functionally similar to arrays. They are specified with commas and parentheses. They are intimately linked with passing parameters to functions and returning values from functions, e.g.\n\n```julia\njulia> function myfunc(a, b)\n           return a*b, a+b\n       end\nmyfunc (generic function with 1 method)\n\njulia> myfunc(1, 2)\n(2, 3)\n```\nWe pass the parameters to the function as a tuple, (a, b). The results are returned as a tuple, (2, 3). Other than passing parameters to functions, what is the use of tuples? They are fairly widely used in Julial. The main differences from arrays are that while arrays are heap-allocated, tuples are stack-allocated. This is some more computer jargon, but what it means is that tuples can be accessed faster than arrays, but cannot be as large.\n\nTuples are also immutable, meaning once created, they cannot be modified. The entries of an array can always be modified. This is important to keep in mind when writing functions in Julia. The only way you can modify a parameter passed to a function is if that parameter is an array. And then only the contents of the array can be changed.\n\nSome examples:\n\n```julia\njulia> a = (1, 2, 3)\n(1, 2, 3)\n\njulia> typeof(a)\nTuple{Int64, Int64, Int64}\n\njulia> b = (1., 2., 3.)\n(1.0, 2.0, 3.0)\n\njulia> typeof(b)\nTuple{Float64, Float64, Float64}\n\njulia> a[2]\n2\n\njulia> c = (1,)\n(1,)\n\njulia> typeof(c)\nTuple{Int64}\n\njulia> d = 1,2,3  # the parentheses are optional here\n(1, 2, 3)\n\njulia> typeof(d)\nTuple{Int64, Int64, Int64}\n```\n\nWe again use `[]` to access the individual entries.\n\nTuples can be unpacked into variables:\n```julia\njulia> a\n(1, 2, 3)\n\njulia> x, y, z = a\n(1, 2, 3)\n\njulia> x\n1\n\njulia> y\n2\n\njulia> z\n3\n```\nAnd since the parentheses are option in the direct specification of tuples, we can do this:\n\n```julia\njulia> x = 1\n1\n\njulia> y = 2\n2\n\njulia> y, x = x, y\n(1, 2)\n\njulia> x\n2\n\njulia> y\n1\n```\nHere we defined a tuple `(x, y)` and then unpacked it into the variables `y` and `x`, swopping their values.\n\nSince tuples have superior performance to arrays, there exists a package that builds small arrays from tuples - [`StaticArrays.jl`](https://github.com/JuliaArrays/StaticArrays.jl). This is commonly used for maximum performance, but only for smallish arrays, typically less than 200-300 entries. More than that and you run out of space on the stack, which has a limited size.\n\n#### Named Tuples\nYou can also name the entries in a tuple and access them via the names instead or indeces:\n\n```julia\njulia> nt = (a = 1, b = 2, c = \"Bob\")\n(a = 1, b = 2, c = \"Bob\")\n\njulia> nt.a\n1\n\njulia> nt[2]\n2\n\njulia> nt.c\n\"Bob\"\n\njulia> typeof(nt)\nNamedTuple{(:a, :b, :c), Tuple{Int64, Int64, String}}\n```\nNote that the entries in a tuple or named tuple needn't be all of the same type. This is also true for arrays, but in that case the array will be of type `Any` and performance will be hugely impacted. Avoid this whenever possible! \n\n#### Ranges\nThe third collection type we are considering are ranges. There are several ways to specify a range:\n\n```julia\njulia> a = 1:10   #start : stop with default step of one, hence a unit range\n1:10\n\njulia> typeof(a)\nUnitRange{Int64}\n\njulia> b = 1:2:20   # start : step : stop, hence a step range\n1:2:19\n\njulia> typeof(b)\nStepRange{Int64, Int64}\n\njulia> c = 1.0:0.5:5.0 # with floating point steps, we get a StepRangeLen - start, stop, length\n1.0:0.5:5.0\n\njulia> typeof(c)\nStepRangeLen{Float64, Base.TwicePrecision{Float64}, Base.TwicePrecision{Float64}, Int64}\n\njulia> d = range(2.0, step=5.3, length=5)  # instead of colon notation, you can call the function with more options\n2.0:5.3:23.2\n\njulia> typeof(d)\nStepRangeLen{Float64, Base.TwicePrecision{Float64}, Base.TwicePrecision{Float64}, Int64}\n```\n\nAnd just like before, we access the entries with `[]`:\n\n```julia\njulia> a[2]\n2\n\njulia> b[3]\n5\n\njulia> c[4]\n2.5\n\njulia> d[5]\n23.2\n```\n\nThe main difference is that, while arrays and tuples consist of values stored in memory, ranges are *lazy*. The values are only calculated when they are requested and no matter the length of the range, it takes up the same amount of memory - just enough to store the *start*, *step* and *stop* values that are needed to calculate any entry and know when you have run through the whole range.\n\n#### Iterables\nArrays, tuples and ranges are all iterable types, meaning you can iterate through their entries:\n\n```julia\njulia> a = [1, 5, 10]\n3-element Vector{Int64}:\n  1\n  5\n 10\n\njulia> for i in a\n           println(i)\n       end\n1\n5\n10\n\njulia> for j in 1:3\n           println(j*2)\n       end\n2\n4\n6\n\njulia> t = (1, 2, 3)\n(1, 2, 3)\n\njulia> for k in t\n           println(k)\n       end\n1\n2\n3\n```\n\nFrom a programmer's point of view, iterable types all behave the same. I can therefore write a function that can handle any iterable type. The only requirement here is that the item passed should have at least two entries, or there will be an error.\n\n```julia\njulia> function mycomp(a)\n           if a[1] > a[2]\n               return true\n           else\n               return false\n           end\n       end\nmycomp (generic function with 1 method)\n\njulia> ar = [1, 2]\n2-element Vector{Int64}:\n 1\n 2\n\njulia> t = (2, 1)\n(2, 1)\n\njulia> r = 10:-1:1\n10:-1:1\n\njulia> mycomp(ar)\nfalse\n\njulia> mycomp(t)\ntrue\n\njulia> mycomp(r)\ntrue\n```\nFor each case, the Julia compiler will generate optimised code depending on the type of the variable passed.\n\n#### Indexing\nIn the examples above, we used one dimensional arrays and there was really no choice in how to index into the structure. In the case if multi-dimensional arrays, there are better and worse options. This is because of how the values are stored in memory. It is faster to sequencially access values that are stored next to each other than to jump around in memory. Julia is *column major*, meaning that the values in the first column of a matrix are stored next to each other in memory, followed by the values of the next column etc. For higher dimenstions, the sequence is similar: each subsequent index follows the next. This is then the fastest way of iterating through the whole array.\n\n\n```julia\njulia> A = rand(10_000, 10_000);  # the _ is ignored - it is just to make reading easier. The ; at the end suppresses output of the result\n\njulia> function myfunc(A)\n           mysum = 0.0\n           m, n = size(A)\n           for i = 1:m, j = 1:n  # we are running through the matrix a row at a time\n               mysum += A[i, j]\n           end\n           return mysum\n       end\nmyfunc (generic function with 1 method)\n\njulia> function myfunc2(A)\n           mysum = 0.0\n           m, n = size(A)\n           for j = 1:n, i = 1:m  # we are running through the matrix a column at a time\n               mysum += A[i, j]\n           end\n           return mysum\n       end\nmyfunc2 (generic function with 1 method)\n\njulia> using BenchmarkTools\n\njulia> @btime myfunc(A) # @btime is similar to @benchmark, but just returns the minimum time\n  1.827 s (1 allocation: 16 bytes)\n5.000090241950586e7\n\njulia> @btime myfunc2(A)\n  96.449 ms (1 allocation: 16 bytes)\n5.000090241950418e7\n```\nSo, in our 10,000 x 10,000 random matrix, summing up the values row-wise takes 1.827s, while column-wise it takes only 96.449ms. Quite the improvement! If you are worried you won't remember the correct way of iterating through a structure, Julia has you covered. Use `eachindex()` to get the optimal sequence:\n\n```julia\njulia> function myfunc3(A)\n           mysum = 0.0\n           m, n = size(A)\n           for i in eachindex(A)\n               mysum += A[i]\n           end\n           return mysum\n       end\nmyfunc3 (generic function with 1 method)\n\njulia> @btime myfunc3(A)\n  96.394 ms (1 allocation: 16 bytes)\n5.000090241950418e7\n```\n\n`eachindex()` returns a linear index, no matter what the dimensionality of the array is and sequences it for the fastest sequencial access.\n\nAnother useful indexing function is `enumerate`. It returns an iterator if tuples, each containing an index and value pair. The indeces are linear, not cartesian.\n\n```julia\njulia> A = rand(2,2)\n2×2 Matrix{Float64}:\n 0.488632  0.177813\n 0.221677  0.559213\n\njulia> for (index, value) in enumerate(A)\n           println(\"$index $value\")\n       end\n1 0.4886321057630626\n2 0.22167740760406662\n3 0.17781317540395236\n4 0.5592126504604934\n```\nFor more information, see the [manual](https://docs.julialang.org/en/v1/base/iterators/#Base.Iterators.enumerate).\n\n## The Type Hierarchy\nThe built-in types have a hieracrchy:\n\n![The type hierarchy - Ref: https://thautwarm.github.io/](https://thautwarm.github.io/Site-32/_images/julia-type-hierarchy.png)\n\nThis consists of abstract and concrete types. You can only instanciate a variable of a concrete type, but the abstracts types are useful to specificy groups of types that would behave similarly, e.g. `Float64` and `Int64` could both the added or multiplied. This is true for all the `Number` types, be they `Real` or `Complex`. We could specify allowed groups of types, via the `<:` operator, or specific types, via `::`, e.g.\n\n```julia\nfunction f(x::T) where T <: Number\n    #do something\nend\n```\n\nHere, Julia will allow us to call f(x) with any sub-type of the `Number` abstract type, such as `Float64`, `Int32` or `ComplexF64`. Calling f(x) with a `String` type will give an error.\n\n\n\n\n\n\n\n\n\n\n\n\n## Type Stability\n Being able to change the type of a variable can be useful, but it does also open the door to something that can cause slowdown in your code: **type instability**. This is when the type of x changes during the execution of your code, making many of the optimisations Julia could do impossible. Instead, additional code is required to handle the type changes. Keep a look-out for something like this:\n\n```julia\njulia> function myfunc(n)\n           sum = 0\n           for i in 1:n\n               sum += 1.5\n           end\n           return sum\n       end\nmyfunc (generic function with 1 method)\n```\n\nAt first glance, there is nothing strange about this code. If you take a closer look however, you will see that `sum` is created as an integer via `sum = 0`, but then we assign floating point values to it.\n\nJulia has a lot of code analyses tools. One of which is `@code_warntype`:\n\n```julia\njulia> @code_warntype myfunc(5)\nMethodInstance for myfunc(::Int64)\n  from myfunc(n) in Main at REPL[20]:1\nArguments\n  #self#::Core.Const(myfunc)\n  n::Int64\nLocals\n  @_3::Union{Nothing, Tuple{Int64, Int64}}\n  sum::Union{Float64, Int64}\n  i::Int64\nBody::Union{Float64, Int64}\n1 ─       (sum = 0)\n│   %2  = (1:n)::Core.PartialStruct(UnitRange{Int64}, Any[Core.Const(1), Int64])\n│         (@_3 = Base.iterate(%2))\n│   %4  = (@_3 === nothing)::Bool\n│   %5  = Base.not_int(%4)::Bool\n└──       goto #4 if not %5\n2 ┄ %7  = @_3::Tuple{Int64, Int64}\n│         (i = Core.getfield(%7, 1))\n│   %9  = Core.getfield(%7, 2)::Int64\n│         (sum = sum + 1.5)\n│         (@_3 = Base.iterate(%2, %9))\n│   %12 = (@_3 === nothing)::Bool\n│   %13 = Base.not_int(%12)::Bool\n└──       goto #4 if not %13\n3 ─       goto #2\n4 ┄       return sum\n```\n\nLike when we looked at the LLVM code generated for a function, this may seem intimidating, but the important bit is this:\n\n```julia\nsum::Union{Float64, Int64}\n```\n\n::: {.callout-note}\nIn the REPL this is helpfully printed in red to draw your attention.\n:::\n\nJulia indicates that the variable `sum` is not type stable. It is assigned both `Int64` and `Float64`values.\n\n"},"formats":{"html":{"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"markdown"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["styles.css"],"toc":true,"output-file":"An_Overview_of_the_Language.html"},"language":{},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.2.335","theme":"cosmo","monofont":"JetBrains Mono","title":"An Overview of the Language"},"extensions":{"book":{"multiFile":true}}}}}