{"title":"Solving Linear Systems","markdown":{"yaml":{"title":"Solving Linear Systems"},"headingText":"Built-in Methods","containsRefs":false,"markdown":"\n\nFor solving systems with smaller, dense matrices, you could use Julia's LinearAlgebra standard library. You can also use the SparseArrays standard library for larger sparse systems. In addition, there are several iterative methods available, such as `IterativeSolver.jl` for solving very large, sparse systems. Rather than learn how several packages work, however, you can use the SciML [`LinearSolve.jl`](https://docs.sciml.ai/LinearSolve/stable/) package that provides a uniform front-end for all the main linear system packages. You can change the solver algorithm by changing a single line of code, which is very convenient when trying to find the most optimal approach for your system.\n\n\nWe shall start by looking at the methods provided by Julia directly. While it may be more convenient to use `LinearSolve.jl` for larger problems, using the Julia base methods is still very useful for quick calculations.\n\n#### Left Division\n\nFor dividing scalar values, we use the `/` (*right division*) operator. There is however also a *left division* operator, `\\`. You can solve a linear system directly as follows:\n\n$$Ax = b$$ $$x = A \\backslash b $$\n\n``` julia\nA = [1 0 3;\n    -1 1 0;\n     2 1 1]\n# 3×3 Matrix{Int64}:\n#   1  0  3\n#  -1  1  0\n#   2  1  1\n\nx = [1, 2, 1]\n# 3-element Vector{Int64}:\n#  1\n#  2\n#  1\n\nb = A*x\n# 3-element Vector{Int64}:\n#  4\n#  1\n#  5\n\nx̂=A\\b # Note that the results are not integers\n# 3-element Vector{Float64}:\n#  1.0\n#  2.0\n#  1.0\n\nx ≈ x̂ # Use approximate check with floats\n# true\n```\n\n::: callout-tip\nIt may help to read `A\\b` as \"A divides into b\"\n:::\n\nThis is a fairly straightforward way of solving a linear system. For dense systems, it is also quite efficient, if your matrix is well-behaved.\n\nInternally, there is quite a bit going on. Julia analyses the matrix, `A`. It then selects an appropriate factorisation methods and uses that to solve the linear system.\n\nUpper and lower triangular and diagonal systems are solved directly via forward or backward substitution. For non-triangular, square matrices, LU factorisation is used.\n\nFor rectangular matrices, a minimum norm, least squares solution is calculated using pivoted QR factorisation.\n\nSimilar approaches are used for sparse matrices, including use of LDL^T^ factorisation for indefinite matrices etc. See the manual section on [factorisation](https://docs.julialang.org/en/v1/stdlib/LinearAlgebra/#LinearAlgebra.factorize) for more detail.\n\nIf you are going to perform more than one calculation with the same matrix, it will be more efficient to store the factorisation result:\n\n``` julia\nusing LinearAlgebra # to import factorize()\n\nA = [1 0 3;\n    -1 1 0;\n     2 1 1]\n# 3×3 Matrix{Int64}:\n#   1  0  3\n#  -1  1  0\n#   2  1  1\n\nA = factorize(A) # replace A with its factorised form\n# LU{Float64, Matrix{Float64}, Vector{Int64}}\n# L factor:\n# 3×3 Matrix{Float64}:\n#   1.0   0.0       0.0\n#  -0.5   1.0       0.0\n#   0.5  -0.333333  1.0\n# U factor:\n# 3×3 Matrix{Float64}:\n#  2.0  1.0  1.0\n#  0.0  1.5  0.5\n#  0.0  0.0  2.66667\n\nA.U # To access the U part\n# 3×3 Matrix{Float64}:\n#  2.0  1.0  1.0\n#  0.0  1.5  0.5\n#  0.0  0.0  2.66667\n\nA.L # To access the L part\n# 3×3 Matrix{Float64}:\n#   1.0   0.0       0.0\n#  -0.5   1.0       0.0\n#   0.5  -0.333333  1.0\n\nb = [4, 1, 5] # Our first b vector\n# 3-element Vector{Int64}:\n#  4\n#  1\n#  5\n\nA\\b # Solve using specialised methods for LU factorised matrices\n# 3-element Vector{Float64}:\n#  1.0\n#  2.0\n#  1.0\n\nb = [1, 2, 7] # A new b vector\n# 3-element Vector{Int64}:\n#  1\n#  2\n#  7\n\nA\\b # Solve without needing to repeat the factorisation\n# 3-element Vector{Float64}:\n#   1.75\n#   3.75\n#  -0.25000000000000006\n```\n\n::: callout-important\nYou could of course solve a linear system by multiplying with the inverse of the matrix, and this is fairly straightforward to do, with `inv(A)`. This is however, **almost never a good choice**, especially with large, sparse matrices, where the inverse is generally dense and may not fit into your computer's memory.\n\nFactorisation is always a better choice, and iterative methods often the best choice for large, sparse matrices.\n:::\n\n#### Specialised Matrix Types\n\nJulia offers several specialised types for matrices with optimised algorithms. These include:\n\n-   Symmetric\n-   Hermitian\n-   UpperTriangular\n-   LowerTriangular\n-   Tridiagonal\n-   Bidiagonal\n-   Diagonal\n-   etc.\n\nSee the [manual](https://docs.julialang.org/en/v1/stdlib/LinearAlgebra/#Special-matrices) for the full list.\n\n#### Sparse Matrices\n\nModels of physical systems very often result in large, sparse matrices. Instead of using a vast amount of memory to store mostly zeros, Julia has a built-in sparse array type. This allows you to save only the non-zero entries and also uses specialised linear algebra methods for sparse matrices. To access this, import the standard library `SparseArrays`.\n\nSparse matrices in Julia are stored in the [*Compressed Sparse Column*](https://en.wikipedia.org/wiki/Sparse_matrix#Compressed_sparse_column_.28CSC_or_CCS.29) format.\n\nSome useful functions for working with sparse matrices include:\n\n-   `nnz()` returns the number of entries in the array. This could include values that have been set to zero.\n    -   `count(!iszero, x)` will check each entry and count only non-zero values\n-   `dropzeros()` will drop entries that have been set to zero from the list of stored entries. It returns a new sparse array\n    -   `dropzeros!()` is similar to `dropzeros()`, but modifies the array directly.\n-   `spzeros(m,n)` is similar to `zeros()` for dense arrays. It creates a `m`x`n` sparse array with all elements set to zero.\n-   `sparse(I, J, V)` creates a sparse array from thee vectors. `I` is a vector of the row indices, `J` of column indices and `V` holds the values of the entries.\n    -   `sparsevec(I, V)` is the vector equivalent of `sparse()`\n    -   `findnz()` is the inverse of `sparse()` and `sparsevec()`\n-   `issparse()` checks is an array is sparse\n-   `blockdiag()` concatenates matrices into a sparse block diagonal matrix.\n\nSee the [manual](https://docs.julialang.org/en/v1/stdlib/SparseArrays/#Sparse-Arrays) for more\n\n## LinearSolve\n\nThe `LinearSolve.jl` package will use the built-in linear algebra methods when appropriate, but also has many other, specialised methods available from several packages. These include iterative methods that are more efficient for large, sparse matrices. It can also make use of your machines's GPU is one is available[^1].\n\n[^1]: This generally means you have a CUDA or OpenCL capable GPU with the appropriate drivers installed\n\nTo install `LinearSolve.jl`, simply use the package manager.\n\nTo illustrate how to use the package, we shall use the same toy examples from before:\n\n``` julia\nusing LinearSolve\n\nA = Float64[1 0 3; # explicitly define as Float64\n    -1 1 0;\n     2 1 1]\n# 3×3 Matrix{Float64}:\n#   1.0  0.0  3.0\n#  -1.0  1.0  0.0\n#   2.0  1.0  1.0\n\nb = Float64[4, 1, 5] # explicitly define as Float64\n# 3-element Vector{Float64}:\n#  4.0\n#  1.0\n#  5.0\n\nprob = LinearProblem(A, b) # Define problem\n# LinearProblem. In-place: true\n# b: 3-element Vector{Float64}:\n#  4.0\n#  1.0\n#  5.0\n\nsol = solve(prob) # and solve\n# u: 3-element Vector{Float64}:\n#  1.0\n#  2.0\n#  1.0\n```\n\nSince LinearSolve has to allow for automatic differentiation[^2], which may require passing *dual variables* to the function, it will implicitly use the type of the variables as specified in `A` in `b`. This will result in an error the inputs are arrays of integers and the if the solution contains fractions. To avoid this, we explicitly define the inputs as `Float64`.\n\n[^2]: Specifically *forward mode* automatic differentiation. See the relevant section for more detail.\n\nYou can also specify which algorithm to use. See the full list and recommendations in the [documentation](https://docs.sciml.ai/LinearSolve/stable/solvers/solvers/).\n\n``` julia\nsol = solve(prob, KrylovJL_GMRES()) #GMRES is an iterative solver, from the Krylov.jl package\n# u: 3-element Vector{Float64}:\n#  1.0000000000000004\n#  2.0000000000000004\n#  0.9999999999999998\n```\n\nIn our example for using built-in methods, we stored the result of the factorisation to re-use this when solving the problem with another `b` vector. We can do the same with LinearSolve by adding one step:\n\n``` julia\nusing LinearSolve\n\nA = Float64[1 0 3;\n    -1 1 0;\n     2 1 1]\n# 3×3 Matrix{Float64}:\n#   1.0  0.0  3.0\n#  -1.0  1.0  0.0\n#   2.0  1.0  1.0\n\nb1 = Float64[4, 1, 5]\n# 3-element Vector{Float64}:\n#  4.0\n#  1.0\n#  5.0\n\nprob = LinearProblem(A, b1)\n# LinearProblem. In-place: true\n# b: 3-element Vector{Float64}:\n#  4.0\n#  1.0\n#  5.0\n\nlinsolve = init(prob) # initialize a cache to store the linear system intermediates\n# LinearSolve.LinearCache{Matrix{Float64}, Vector{Float64}, Vector{Float64}, SciMLBase.NullParameters, Nothing, LU{Float64, Matrix{Float64}, Vector{Int64}}, SciMLOperators.IdentityOperator, SciMLOperators.IdentityOperator, Float64, true}([1.0 0.0 3.0; -1.0 1.0 0.0; 2.0 1.0 1.0], [4.0, 1.0, 5.0], [0.0, 0.0, 0.0], SciMLBase.NullParameters(), nothing, LU{Float64, Matrix{Float64}, Vector{Int64}}(Matrix{Float64}(undef, 0, 0), Int64[], 0), true, SciMLOperators.IdentityOperator(3), SciMLOperators.IdentityOperator(3), 1.4901161193847656e-8, 1.4901161193847656e-8, 3, false, LinearSolve.OperatorAssumptions{true}())\n\nsol1 = solve(linsolve) # solve the problem, using the cache\n# u: 3-element Vector{Float64}:\n#  1.0\n#  2.0\n#  1.0\n\nb2 = Float64[1, 2, 7] # another b vector\n# 3-element Vector{Float64}:\n#  1.0\n#  2.0\n#  7.0\n\nlinsolve = LinearSolve.set_b(sol1.cache, b2) # update the cache with the new b vector\n# LinearSolve.LinearCache{Matrix{Float64}, Vector{Float64}, Vector{Float64}, SciMLBase.NullParameters, Nothing, LU{Float64, Matrix{Float64}, Vector{Int64}}, SciMLOperators.IdentityOperator, SciMLOperators.IdentityOperator, Float64, true}([2.0 1.0 1.0; -0.5 1.5 0.5; 0.5 -0.3333333333333333 2.6666666666666665], [1.0, 2.0, 7.0], [1.0, 2.0, 1.0], SciMLBase.NullParameters(), nothing, LU{Float64, Matrix{Float64}, Vector{Int64}}([2.0 1.0 1.0; -0.5 1.5 0.5; 0.5 -0.3333333333333333 2.6666666666666665], [3, 2, 3], 0), false, SciMLOperators.IdentityOperator(3), SciMLOperators.IdentityOperator(3), 1.4901161193847656e-8, 1.4901161193847656e-8, 3, false, LinearSolve.OperatorAssumptions{true}())\n\nsol2 = solve(linsolve) # and solve again\n# u: 3-element Vector{Float64}:\n#   1.75\n#   3.75\n#  -0.25000000000000006\n```","srcMarkdownNoYaml":"\n\nFor solving systems with smaller, dense matrices, you could use Julia's LinearAlgebra standard library. You can also use the SparseArrays standard library for larger sparse systems. In addition, there are several iterative methods available, such as `IterativeSolver.jl` for solving very large, sparse systems. Rather than learn how several packages work, however, you can use the SciML [`LinearSolve.jl`](https://docs.sciml.ai/LinearSolve/stable/) package that provides a uniform front-end for all the main linear system packages. You can change the solver algorithm by changing a single line of code, which is very convenient when trying to find the most optimal approach for your system.\n\n## Built-in Methods\n\nWe shall start by looking at the methods provided by Julia directly. While it may be more convenient to use `LinearSolve.jl` for larger problems, using the Julia base methods is still very useful for quick calculations.\n\n#### Left Division\n\nFor dividing scalar values, we use the `/` (*right division*) operator. There is however also a *left division* operator, `\\`. You can solve a linear system directly as follows:\n\n$$Ax = b$$ $$x = A \\backslash b $$\n\n``` julia\nA = [1 0 3;\n    -1 1 0;\n     2 1 1]\n# 3×3 Matrix{Int64}:\n#   1  0  3\n#  -1  1  0\n#   2  1  1\n\nx = [1, 2, 1]\n# 3-element Vector{Int64}:\n#  1\n#  2\n#  1\n\nb = A*x\n# 3-element Vector{Int64}:\n#  4\n#  1\n#  5\n\nx̂=A\\b # Note that the results are not integers\n# 3-element Vector{Float64}:\n#  1.0\n#  2.0\n#  1.0\n\nx ≈ x̂ # Use approximate check with floats\n# true\n```\n\n::: callout-tip\nIt may help to read `A\\b` as \"A divides into b\"\n:::\n\nThis is a fairly straightforward way of solving a linear system. For dense systems, it is also quite efficient, if your matrix is well-behaved.\n\nInternally, there is quite a bit going on. Julia analyses the matrix, `A`. It then selects an appropriate factorisation methods and uses that to solve the linear system.\n\nUpper and lower triangular and diagonal systems are solved directly via forward or backward substitution. For non-triangular, square matrices, LU factorisation is used.\n\nFor rectangular matrices, a minimum norm, least squares solution is calculated using pivoted QR factorisation.\n\nSimilar approaches are used for sparse matrices, including use of LDL^T^ factorisation for indefinite matrices etc. See the manual section on [factorisation](https://docs.julialang.org/en/v1/stdlib/LinearAlgebra/#LinearAlgebra.factorize) for more detail.\n\nIf you are going to perform more than one calculation with the same matrix, it will be more efficient to store the factorisation result:\n\n``` julia\nusing LinearAlgebra # to import factorize()\n\nA = [1 0 3;\n    -1 1 0;\n     2 1 1]\n# 3×3 Matrix{Int64}:\n#   1  0  3\n#  -1  1  0\n#   2  1  1\n\nA = factorize(A) # replace A with its factorised form\n# LU{Float64, Matrix{Float64}, Vector{Int64}}\n# L factor:\n# 3×3 Matrix{Float64}:\n#   1.0   0.0       0.0\n#  -0.5   1.0       0.0\n#   0.5  -0.333333  1.0\n# U factor:\n# 3×3 Matrix{Float64}:\n#  2.0  1.0  1.0\n#  0.0  1.5  0.5\n#  0.0  0.0  2.66667\n\nA.U # To access the U part\n# 3×3 Matrix{Float64}:\n#  2.0  1.0  1.0\n#  0.0  1.5  0.5\n#  0.0  0.0  2.66667\n\nA.L # To access the L part\n# 3×3 Matrix{Float64}:\n#   1.0   0.0       0.0\n#  -0.5   1.0       0.0\n#   0.5  -0.333333  1.0\n\nb = [4, 1, 5] # Our first b vector\n# 3-element Vector{Int64}:\n#  4\n#  1\n#  5\n\nA\\b # Solve using specialised methods for LU factorised matrices\n# 3-element Vector{Float64}:\n#  1.0\n#  2.0\n#  1.0\n\nb = [1, 2, 7] # A new b vector\n# 3-element Vector{Int64}:\n#  1\n#  2\n#  7\n\nA\\b # Solve without needing to repeat the factorisation\n# 3-element Vector{Float64}:\n#   1.75\n#   3.75\n#  -0.25000000000000006\n```\n\n::: callout-important\nYou could of course solve a linear system by multiplying with the inverse of the matrix, and this is fairly straightforward to do, with `inv(A)`. This is however, **almost never a good choice**, especially with large, sparse matrices, where the inverse is generally dense and may not fit into your computer's memory.\n\nFactorisation is always a better choice, and iterative methods often the best choice for large, sparse matrices.\n:::\n\n#### Specialised Matrix Types\n\nJulia offers several specialised types for matrices with optimised algorithms. These include:\n\n-   Symmetric\n-   Hermitian\n-   UpperTriangular\n-   LowerTriangular\n-   Tridiagonal\n-   Bidiagonal\n-   Diagonal\n-   etc.\n\nSee the [manual](https://docs.julialang.org/en/v1/stdlib/LinearAlgebra/#Special-matrices) for the full list.\n\n#### Sparse Matrices\n\nModels of physical systems very often result in large, sparse matrices. Instead of using a vast amount of memory to store mostly zeros, Julia has a built-in sparse array type. This allows you to save only the non-zero entries and also uses specialised linear algebra methods for sparse matrices. To access this, import the standard library `SparseArrays`.\n\nSparse matrices in Julia are stored in the [*Compressed Sparse Column*](https://en.wikipedia.org/wiki/Sparse_matrix#Compressed_sparse_column_.28CSC_or_CCS.29) format.\n\nSome useful functions for working with sparse matrices include:\n\n-   `nnz()` returns the number of entries in the array. This could include values that have been set to zero.\n    -   `count(!iszero, x)` will check each entry and count only non-zero values\n-   `dropzeros()` will drop entries that have been set to zero from the list of stored entries. It returns a new sparse array\n    -   `dropzeros!()` is similar to `dropzeros()`, but modifies the array directly.\n-   `spzeros(m,n)` is similar to `zeros()` for dense arrays. It creates a `m`x`n` sparse array with all elements set to zero.\n-   `sparse(I, J, V)` creates a sparse array from thee vectors. `I` is a vector of the row indices, `J` of column indices and `V` holds the values of the entries.\n    -   `sparsevec(I, V)` is the vector equivalent of `sparse()`\n    -   `findnz()` is the inverse of `sparse()` and `sparsevec()`\n-   `issparse()` checks is an array is sparse\n-   `blockdiag()` concatenates matrices into a sparse block diagonal matrix.\n\nSee the [manual](https://docs.julialang.org/en/v1/stdlib/SparseArrays/#Sparse-Arrays) for more\n\n## LinearSolve\n\nThe `LinearSolve.jl` package will use the built-in linear algebra methods when appropriate, but also has many other, specialised methods available from several packages. These include iterative methods that are more efficient for large, sparse matrices. It can also make use of your machines's GPU is one is available[^1].\n\n[^1]: This generally means you have a CUDA or OpenCL capable GPU with the appropriate drivers installed\n\nTo install `LinearSolve.jl`, simply use the package manager.\n\nTo illustrate how to use the package, we shall use the same toy examples from before:\n\n``` julia\nusing LinearSolve\n\nA = Float64[1 0 3; # explicitly define as Float64\n    -1 1 0;\n     2 1 1]\n# 3×3 Matrix{Float64}:\n#   1.0  0.0  3.0\n#  -1.0  1.0  0.0\n#   2.0  1.0  1.0\n\nb = Float64[4, 1, 5] # explicitly define as Float64\n# 3-element Vector{Float64}:\n#  4.0\n#  1.0\n#  5.0\n\nprob = LinearProblem(A, b) # Define problem\n# LinearProblem. In-place: true\n# b: 3-element Vector{Float64}:\n#  4.0\n#  1.0\n#  5.0\n\nsol = solve(prob) # and solve\n# u: 3-element Vector{Float64}:\n#  1.0\n#  2.0\n#  1.0\n```\n\nSince LinearSolve has to allow for automatic differentiation[^2], which may require passing *dual variables* to the function, it will implicitly use the type of the variables as specified in `A` in `b`. This will result in an error the inputs are arrays of integers and the if the solution contains fractions. To avoid this, we explicitly define the inputs as `Float64`.\n\n[^2]: Specifically *forward mode* automatic differentiation. See the relevant section for more detail.\n\nYou can also specify which algorithm to use. See the full list and recommendations in the [documentation](https://docs.sciml.ai/LinearSolve/stable/solvers/solvers/).\n\n``` julia\nsol = solve(prob, KrylovJL_GMRES()) #GMRES is an iterative solver, from the Krylov.jl package\n# u: 3-element Vector{Float64}:\n#  1.0000000000000004\n#  2.0000000000000004\n#  0.9999999999999998\n```\n\nIn our example for using built-in methods, we stored the result of the factorisation to re-use this when solving the problem with another `b` vector. We can do the same with LinearSolve by adding one step:\n\n``` julia\nusing LinearSolve\n\nA = Float64[1 0 3;\n    -1 1 0;\n     2 1 1]\n# 3×3 Matrix{Float64}:\n#   1.0  0.0  3.0\n#  -1.0  1.0  0.0\n#   2.0  1.0  1.0\n\nb1 = Float64[4, 1, 5]\n# 3-element Vector{Float64}:\n#  4.0\n#  1.0\n#  5.0\n\nprob = LinearProblem(A, b1)\n# LinearProblem. In-place: true\n# b: 3-element Vector{Float64}:\n#  4.0\n#  1.0\n#  5.0\n\nlinsolve = init(prob) # initialize a cache to store the linear system intermediates\n# LinearSolve.LinearCache{Matrix{Float64}, Vector{Float64}, Vector{Float64}, SciMLBase.NullParameters, Nothing, LU{Float64, Matrix{Float64}, Vector{Int64}}, SciMLOperators.IdentityOperator, SciMLOperators.IdentityOperator, Float64, true}([1.0 0.0 3.0; -1.0 1.0 0.0; 2.0 1.0 1.0], [4.0, 1.0, 5.0], [0.0, 0.0, 0.0], SciMLBase.NullParameters(), nothing, LU{Float64, Matrix{Float64}, Vector{Int64}}(Matrix{Float64}(undef, 0, 0), Int64[], 0), true, SciMLOperators.IdentityOperator(3), SciMLOperators.IdentityOperator(3), 1.4901161193847656e-8, 1.4901161193847656e-8, 3, false, LinearSolve.OperatorAssumptions{true}())\n\nsol1 = solve(linsolve) # solve the problem, using the cache\n# u: 3-element Vector{Float64}:\n#  1.0\n#  2.0\n#  1.0\n\nb2 = Float64[1, 2, 7] # another b vector\n# 3-element Vector{Float64}:\n#  1.0\n#  2.0\n#  7.0\n\nlinsolve = LinearSolve.set_b(sol1.cache, b2) # update the cache with the new b vector\n# LinearSolve.LinearCache{Matrix{Float64}, Vector{Float64}, Vector{Float64}, SciMLBase.NullParameters, Nothing, LU{Float64, Matrix{Float64}, Vector{Int64}}, SciMLOperators.IdentityOperator, SciMLOperators.IdentityOperator, Float64, true}([2.0 1.0 1.0; -0.5 1.5 0.5; 0.5 -0.3333333333333333 2.6666666666666665], [1.0, 2.0, 7.0], [1.0, 2.0, 1.0], SciMLBase.NullParameters(), nothing, LU{Float64, Matrix{Float64}, Vector{Int64}}([2.0 1.0 1.0; -0.5 1.5 0.5; 0.5 -0.3333333333333333 2.6666666666666665], [3, 2, 3], 0), false, SciMLOperators.IdentityOperator(3), SciMLOperators.IdentityOperator(3), 1.4901161193847656e-8, 1.4901161193847656e-8, 3, false, LinearSolve.OperatorAssumptions{true}())\n\nsol2 = solve(linsolve) # and solve again\n# u: 3-element Vector{Float64}:\n#   1.75\n#   3.75\n#  -0.25000000000000006\n```"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"markdown"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true,"format-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["styles.css"],"toc":true,"embed-resources":true,"output-file":"06_Solving_Linear_Systems.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.3.361","theme":"cosmo","monofont":"JetBrains Mono","smooth-scroll":false,"footnotes-hover":true,"title":"Solving Linear Systems"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}